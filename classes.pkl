for intent in intents['intents']:
   for pattern in intent['patterns']:

       #tokenizing each word in a sentence
       w = nltk.word_tokenize(pattern)
       words.extend(w)
       documents.append((w,intent['tag']))

       if intent['tag'] not in classes:
           classes.append(intent['tag'])


